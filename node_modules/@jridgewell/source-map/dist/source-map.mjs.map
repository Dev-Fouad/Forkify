{"version":3,"file":"source-map.mjs","sources":["../node_modules/@jridgewell/sourcemap-codec/dist/sourcemap-codec.mjs","../node_modules/@jridgewell/resolve-uri/dist/resolve-uri.mjs","../node_modules/@jridgewell/trace-mapping/dist/trace-mapping.mjs","../node_modules/@jridgewell/set-array/dist/set-array.mjs","../node_modules/@jridgewell/gen-mapping/dist/gen-mapping.mjs","../../src/source-map.ts"],"sourcesContent":["const comma = ','.charCodeAt(0);\nconst semicolon = ';'.charCodeAt(0);\nconst chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';\nconst intToChar = new Uint8Array(64); // 64 possible chars.\nconst charToInteger = new Uint8Array(128); // z is 122 in ASCII\nfor (let i = 0; i < chars.length; i++) {\n    const c = chars.charCodeAt(i);\n    charToInteger[c] = i;\n    intToChar[i] = c;\n}\n// Provide a fallback for older environments.\nconst td = typeof TextDecoder !== 'undefined'\n    ? new TextDecoder()\n    : typeof Buffer !== 'undefined'\n        ? {\n            decode(buf) {\n                const out = Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength);\n                return out.toString();\n            },\n        }\n        : {\n            decode(buf) {\n                let out = '';\n                for (let i = 0; i < buf.length; i++) {\n                    out += String.fromCharCode(buf[i]);\n                }\n                return out;\n            },\n        };\nfunction decode(mappings) {\n    const state = new Int32Array(5);\n    const decoded = [];\n    let line = [];\n    let sorted = true;\n    let lastCol = 0;\n    for (let i = 0; i < mappings.length;) {\n        const c = mappings.charCodeAt(i);\n        if (c === comma) {\n            i++;\n        }\n        else if (c === semicolon) {\n            state[0] = lastCol = 0;\n            if (!sorted)\n                sort(line);\n            sorted = true;\n            decoded.push(line);\n            line = [];\n            i++;\n        }\n        else {\n            i = decodeInteger(mappings, i, state, 0); // generatedCodeColumn\n            const col = state[0];\n            if (col < lastCol)\n                sorted = false;\n            lastCol = col;\n            if (!hasMoreSegments(mappings, i)) {\n                line.push([col]);\n                continue;\n            }\n            i = decodeInteger(mappings, i, state, 1); // sourceFileIndex\n            i = decodeInteger(mappings, i, state, 2); // sourceCodeLine\n            i = decodeInteger(mappings, i, state, 3); // sourceCodeColumn\n            if (!hasMoreSegments(mappings, i)) {\n                line.push([col, state[1], state[2], state[3]]);\n                continue;\n            }\n            i = decodeInteger(mappings, i, state, 4); // nameIndex\n            line.push([col, state[1], state[2], state[3], state[4]]);\n        }\n    }\n    if (!sorted)\n        sort(line);\n    decoded.push(line);\n    return decoded;\n}\nfunction decodeInteger(mappings, pos, state, j) {\n    let value = 0;\n    let shift = 0;\n    let integer = 0;\n    do {\n        const c = mappings.charCodeAt(pos++);\n        integer = charToInteger[c];\n        value |= (integer & 31) << shift;\n        shift += 5;\n    } while (integer & 32);\n    const shouldNegate = value & 1;\n    value >>>= 1;\n    if (shouldNegate) {\n        value = -0x80000000 | -value;\n    }\n    state[j] += value;\n    return pos;\n}\nfunction hasMoreSegments(mappings, i) {\n    if (i >= mappings.length)\n        return false;\n    const c = mappings.charCodeAt(i);\n    if (c === comma || c === semicolon)\n        return false;\n    return true;\n}\nfunction sort(line) {\n    line.sort(sortComparator);\n}\nfunction sortComparator(a, b) {\n    return a[0] - b[0];\n}\nfunction encode(decoded) {\n    const state = new Int32Array(5);\n    let buf = new Uint8Array(1024);\n    let pos = 0;\n    for (let i = 0; i < decoded.length; i++) {\n        const line = decoded[i];\n        if (i > 0) {\n            buf = reserve(buf, pos, 1);\n            buf[pos++] = semicolon;\n        }\n        if (line.length === 0)\n            continue;\n        state[0] = 0;\n        for (let j = 0; j < line.length; j++) {\n            const segment = line[j];\n            // We can push up to 5 ints, each int can take at most 7 chars, and we\n            // may push a comma.\n            buf = reserve(buf, pos, 36);\n            if (j > 0)\n                buf[pos++] = comma;\n            pos = encodeInteger(buf, pos, state, segment, 0); // generatedCodeColumn\n            if (segment.length === 1)\n                continue;\n            pos = encodeInteger(buf, pos, state, segment, 1); // sourceFileIndex\n            pos = encodeInteger(buf, pos, state, segment, 2); // sourceCodeLine\n            pos = encodeInteger(buf, pos, state, segment, 3); // sourceCodeColumn\n            if (segment.length === 4)\n                continue;\n            pos = encodeInteger(buf, pos, state, segment, 4); // nameIndex\n        }\n    }\n    return td.decode(buf.subarray(0, pos));\n}\nfunction reserve(buf, pos, count) {\n    if (buf.length > pos + count)\n        return buf;\n    const swap = new Uint8Array(buf.length * 2);\n    swap.set(buf);\n    return swap;\n}\nfunction encodeInteger(buf, pos, state, segment, j) {\n    const next = segment[j];\n    let num = next - state[j];\n    state[j] = next;\n    num = num < 0 ? (-num << 1) | 1 : num << 1;\n    do {\n        let clamped = num & 0b011111;\n        num >>>= 5;\n        if (num > 0)\n            clamped |= 0b100000;\n        buf[pos++] = intToChar[clamped];\n    } while (num > 0);\n    return pos;\n}\n\nexport { decode, encode };\n//# sourceMappingURL=sourcemap-codec.mjs.map\n","// Matches the scheme of a URL, eg \"http://\"\nconst schemeRegex = /^[\\w+.-]+:\\/\\//;\n/**\n * Matches the parts of a URL:\n * 1. Scheme, including \":\", guaranteed.\n * 2. User/password, including \"@\", optional.\n * 3. Host, guaranteed.\n * 4. Port, including \":\", optional.\n * 5. Path, including \"/\", optional.\n */\nconst urlRegex = /^([\\w+.-]+:)\\/\\/([^@/#?]*@)?([^:/#?]*)(:\\d+)?(\\/[^#?]*)?/;\n/**\n * File URLs are weird. They dont' need the regular `//` in the scheme, they may or may not start\n * with a leading `/`, they can have a domain (but only if they don't start with a Windows drive).\n *\n * 1. Host, optional.\n * 2. Path, which may inclue \"/\", guaranteed.\n */\nconst fileRegex = /^file:(?:\\/\\/((?![a-z]:)[^/]*)?)?(\\/?.*)/i;\nfunction isAbsoluteUrl(input) {\n    return schemeRegex.test(input);\n}\nfunction isSchemeRelativeUrl(input) {\n    return input.startsWith('//');\n}\nfunction isAbsolutePath(input) {\n    return input.startsWith('/');\n}\nfunction isFileUrl(input) {\n    return input.startsWith('file:');\n}\nfunction parseAbsoluteUrl(input) {\n    const match = urlRegex.exec(input);\n    return makeUrl(match[1], match[2] || '', match[3], match[4] || '', match[5] || '/');\n}\nfunction parseFileUrl(input) {\n    const match = fileRegex.exec(input);\n    const path = match[2];\n    return makeUrl('file:', '', match[1] || '', '', isAbsolutePath(path) ? path : '/' + path);\n}\nfunction makeUrl(scheme, user, host, port, path) {\n    return {\n        scheme,\n        user,\n        host,\n        port,\n        path,\n        relativePath: false,\n    };\n}\nfunction parseUrl(input) {\n    if (isSchemeRelativeUrl(input)) {\n        const url = parseAbsoluteUrl('http:' + input);\n        url.scheme = '';\n        return url;\n    }\n    if (isAbsolutePath(input)) {\n        const url = parseAbsoluteUrl('http://foo.com' + input);\n        url.scheme = '';\n        url.host = '';\n        return url;\n    }\n    if (isFileUrl(input))\n        return parseFileUrl(input);\n    if (isAbsoluteUrl(input))\n        return parseAbsoluteUrl(input);\n    const url = parseAbsoluteUrl('http://foo.com/' + input);\n    url.scheme = '';\n    url.host = '';\n    url.relativePath = true;\n    return url;\n}\nfunction stripPathFilename(path) {\n    // If a path ends with a parent directory \"..\", then it's a relative path with excess parent\n    // paths. It's not a file, so we can't strip it.\n    if (path.endsWith('/..'))\n        return path;\n    const index = path.lastIndexOf('/');\n    return path.slice(0, index + 1);\n}\nfunction mergePaths(url, base) {\n    // If we're not a relative path, then we're an absolute path, and it doesn't matter what base is.\n    if (!url.relativePath)\n        return;\n    normalizePath(base);\n    // If the path is just a \"/\", then it was an empty path to begin with (remember, we're a relative\n    // path).\n    if (url.path === '/') {\n        url.path = base.path;\n    }\n    else {\n        // Resolution happens relative to the base path's directory, not the file.\n        url.path = stripPathFilename(base.path) + url.path;\n    }\n    // If the base path is absolute, then our path is now absolute too.\n    url.relativePath = base.relativePath;\n}\n/**\n * The path can have empty directories \"//\", unneeded parents \"foo/..\", or current directory\n * \"foo/.\". We need to normalize to a standard representation.\n */\nfunction normalizePath(url) {\n    const { relativePath } = url;\n    const pieces = url.path.split('/');\n    // We need to preserve the first piece always, so that we output a leading slash. The item at\n    // pieces[0] is an empty string.\n    let pointer = 1;\n    // Positive is the number of real directories we've output, used for popping a parent directory.\n    // Eg, \"foo/bar/..\" will have a positive 2, and we can decrement to be left with just \"foo\".\n    let positive = 0;\n    // We need to keep a trailing slash if we encounter an empty directory (eg, splitting \"foo/\" will\n    // generate `[\"foo\", \"\"]` pieces). And, if we pop a parent directory. But once we encounter a\n    // real directory, we won't need to append, unless the other conditions happen again.\n    let addTrailingSlash = false;\n    for (let i = 1; i < pieces.length; i++) {\n        const piece = pieces[i];\n        // An empty directory, could be a trailing slash, or just a double \"//\" in the path.\n        if (!piece) {\n            addTrailingSlash = true;\n            continue;\n        }\n        // If we encounter a real directory, then we don't need to append anymore.\n        addTrailingSlash = false;\n        // A current directory, which we can always drop.\n        if (piece === '.')\n            continue;\n        // A parent directory, we need to see if there are any real directories we can pop. Else, we\n        // have an excess of parents, and we'll need to keep the \"..\".\n        if (piece === '..') {\n            if (positive) {\n                addTrailingSlash = true;\n                positive--;\n                pointer--;\n            }\n            else if (relativePath) {\n                // If we're in a relativePath, then we need to keep the excess parents. Else, in an absolute\n                // URL, protocol relative URL, or an absolute path, we don't need to keep excess.\n                pieces[pointer++] = piece;\n            }\n            continue;\n        }\n        // We've encountered a real directory. Move it to the next insertion pointer, which accounts for\n        // any popped or dropped directories.\n        pieces[pointer++] = piece;\n        positive++;\n    }\n    let path = '';\n    for (let i = 1; i < pointer; i++) {\n        path += '/' + pieces[i];\n    }\n    if (!path || (addTrailingSlash && !path.endsWith('/..'))) {\n        path += '/';\n    }\n    url.path = path;\n}\n/**\n * Attempts to resolve `input` URL/path relative to `base`.\n */\nfunction resolve(input, base) {\n    if (!input && !base)\n        return '';\n    const url = parseUrl(input);\n    // If we have a base, and the input isn't already an absolute URL, then we need to merge.\n    if (base && !url.scheme) {\n        const baseUrl = parseUrl(base);\n        url.scheme = baseUrl.scheme;\n        // If there's no host, then we were just a path.\n        if (!url.host) {\n            // The host, user, and port are joined, you can't copy one without the others.\n            url.user = baseUrl.user;\n            url.host = baseUrl.host;\n            url.port = baseUrl.port;\n        }\n        mergePaths(url, baseUrl);\n    }\n    normalizePath(url);\n    // If the input (and base, if there was one) are both relative, then we need to output a relative.\n    if (url.relativePath) {\n        // The first char is always a \"/\".\n        const path = url.path.slice(1);\n        if (!path)\n            return '.';\n        // If base started with a leading \".\", or there is no base and input started with a \".\", then we\n        // need to ensure that the relative path starts with a \".\". We don't know if relative starts\n        // with a \"..\", though, so check before prepending.\n        const keepRelative = (base || input).startsWith('.');\n        return !keepRelative || path.startsWith('.') ? path : './' + path;\n    }\n    // If there's no host (and no scheme/user/port), then we need to output an absolute path.\n    if (!url.scheme && !url.host)\n        return url.path;\n    // We're outputting either an absolute URL, or a protocol relative one.\n    return `${url.scheme}//${url.user}${url.host}${url.port}${url.path}`;\n}\n\nexport { resolve as default };\n//# sourceMappingURL=resolve-uri.mjs.map\n","import { encode, decode } from '@jridgewell/sourcemap-codec';\nimport resolveUri from '@jridgewell/resolve-uri';\n\nfunction resolve(input, base) {\n    // The base is always treated as a directory, if it's not empty.\n    // https://github.com/mozilla/source-map/blob/8cb3ee57/lib/util.js#L327\n    // https://github.com/chromium/chromium/blob/da4adbb3/third_party/blink/renderer/devtools/front_end/sdk/SourceMap.js#L400-L401\n    if (base && !base.endsWith('/'))\n        base += '/';\n    return resolveUri(input, base);\n}\n\n/**\n * Removes everything after the last \"/\", but leaves the slash.\n */\nfunction stripFilename(path) {\n    if (!path)\n        return '';\n    const index = path.lastIndexOf('/');\n    return path.slice(0, index + 1);\n}\n\nconst COLUMN = 0;\nconst SOURCES_INDEX = 1;\nconst SOURCE_LINE = 2;\nconst SOURCE_COLUMN = 3;\nconst NAMES_INDEX = 4;\nconst REV_GENERATED_LINE = 1;\nconst REV_GENERATED_COLUMN = 2;\n\nfunction maybeSort(mappings, owned) {\n    const unsortedIndex = nextUnsortedSegmentLine(mappings, 0);\n    if (unsortedIndex === mappings.length)\n        return mappings;\n    // If we own the array (meaning we parsed it from JSON), then we're free to directly mutate it. If\n    // not, we do not want to modify the consumer's input array.\n    if (!owned)\n        mappings = mappings.slice();\n    for (let i = unsortedIndex; i < mappings.length; i = nextUnsortedSegmentLine(mappings, i + 1)) {\n        mappings[i] = sortSegments(mappings[i], owned);\n    }\n    return mappings;\n}\nfunction nextUnsortedSegmentLine(mappings, start) {\n    for (let i = start; i < mappings.length; i++) {\n        if (!isSorted(mappings[i]))\n            return i;\n    }\n    return mappings.length;\n}\nfunction isSorted(line) {\n    for (let j = 1; j < line.length; j++) {\n        if (line[j][COLUMN] < line[j - 1][COLUMN]) {\n            return false;\n        }\n    }\n    return true;\n}\nfunction sortSegments(line, owned) {\n    if (!owned)\n        line = line.slice();\n    return line.sort(sortComparator);\n}\nfunction sortComparator(a, b) {\n    return a[COLUMN] - b[COLUMN];\n}\n\nlet found = false;\n/**\n * A binary search implementation that returns the index if a match is found.\n * If no match is found, then the left-index (the index associated with the item that comes just\n * before the desired index) is returned. To maintain proper sort order, a splice would happen at\n * the next index:\n *\n * ```js\n * const array = [1, 3];\n * const needle = 2;\n * const index = binarySearch(array, needle, (item, needle) => item - needle);\n *\n * assert.equal(index, 0);\n * array.splice(index + 1, 0, needle);\n * assert.deepEqual(array, [1, 2, 3]);\n * ```\n */\nfunction binarySearch(haystack, needle, low, high) {\n    while (low <= high) {\n        const mid = low + ((high - low) >> 1);\n        const cmp = haystack[mid][COLUMN] - needle;\n        if (cmp === 0) {\n            found = true;\n            return mid;\n        }\n        if (cmp < 0) {\n            low = mid + 1;\n        }\n        else {\n            high = mid - 1;\n        }\n    }\n    found = false;\n    return low - 1;\n}\nfunction upperBound(haystack, needle, index) {\n    for (let i = index + 1; i < haystack.length; i++, index++) {\n        if (haystack[i][COLUMN] !== needle)\n            break;\n    }\n    return index;\n}\nfunction lowerBound(haystack, needle, index) {\n    for (let i = index - 1; i >= 0; i--, index--) {\n        if (haystack[i][COLUMN] !== needle)\n            break;\n    }\n    return index;\n}\nfunction memoizedState() {\n    return {\n        lastKey: -1,\n        lastNeedle: -1,\n        lastIndex: -1,\n    };\n}\n/**\n * This overly complicated beast is just to record the last tested line/column and the resulting\n * index, allowing us to skip a few tests if mappings are monotonically increasing.\n */\nfunction memoizedBinarySearch(haystack, needle, state, key) {\n    const { lastKey, lastNeedle, lastIndex } = state;\n    let low = 0;\n    let high = haystack.length - 1;\n    if (key === lastKey) {\n        if (needle === lastNeedle) {\n            found = lastIndex !== -1 && haystack[lastIndex][COLUMN] === needle;\n            return lastIndex;\n        }\n        if (needle >= lastNeedle) {\n            // lastIndex may be -1 if the previous needle was not found.\n            low = lastIndex === -1 ? 0 : lastIndex;\n        }\n        else {\n            high = lastIndex;\n        }\n    }\n    state.lastKey = key;\n    state.lastNeedle = needle;\n    return (state.lastIndex = binarySearch(haystack, needle, low, high));\n}\n\n// Rebuilds the original source files, with mappings that are ordered by source line/column instead\n// of generated line/column.\nfunction buildBySources(decoded, memos) {\n    const sources = memos.map(buildNullArray);\n    for (let i = 0; i < decoded.length; i++) {\n        const line = decoded[i];\n        for (let j = 0; j < line.length; j++) {\n            const seg = line[j];\n            if (seg.length === 1)\n                continue;\n            const sourceIndex = seg[SOURCES_INDEX];\n            const sourceLine = seg[SOURCE_LINE];\n            const sourceColumn = seg[SOURCE_COLUMN];\n            const originalSource = sources[sourceIndex];\n            const originalLine = (originalSource[sourceLine] || (originalSource[sourceLine] = []));\n            const memo = memos[sourceIndex];\n            // The binary search either found a match, or it found the left-index just before where the\n            // segment should go. Either way, we want to insert after that. And there may be multiple\n            // generated segments associated with an original location, so there may need to move several\n            // indexes before we find where we need to insert.\n            const index = upperBound(originalLine, sourceColumn, memoizedBinarySearch(originalLine, sourceColumn, memo, sourceLine));\n            insert(originalLine, (memo.lastIndex = index + 1), [sourceColumn, i, seg[COLUMN]]);\n        }\n    }\n    return sources;\n}\nfunction insert(array, index, value) {\n    for (let i = array.length; i > index; i--) {\n        array[i] = array[i - 1];\n    }\n    array[index] = value;\n}\n// Null arrays allow us to use ordered index keys without actually allocating contiguous memory like\n// a real array. We use a null-prototype object to avoid prototype pollution and deoptimizations.\n// Numeric properties on objects are magically sorted in ascending order by the engine regardless of\n// the insertion order. So, by setting any numeric keys, even out of order, we'll get ascending\n// order when iterating with for-in.\nfunction buildNullArray() {\n    return { __proto__: null };\n}\n\nconst AnyMap = function (map, mapUrl) {\n    const parsed = typeof map === 'string' ? JSON.parse(map) : map;\n    if (!('sections' in parsed))\n        return new TraceMap(parsed, mapUrl);\n    const mappings = [];\n    const sources = [];\n    const sourcesContent = [];\n    const names = [];\n    const { sections } = parsed;\n    let i = 0;\n    for (; i < sections.length - 1; i++) {\n        const no = sections[i + 1].offset;\n        addSection(sections[i], mapUrl, mappings, sources, sourcesContent, names, no.line, no.column);\n    }\n    if (sections.length > 0) {\n        addSection(sections[i], mapUrl, mappings, sources, sourcesContent, names, Infinity, Infinity);\n    }\n    const joined = {\n        version: 3,\n        file: parsed.file,\n        names,\n        sources,\n        sourcesContent,\n        mappings,\n    };\n    return presortedDecodedMap(joined);\n};\nfunction addSection(section, mapUrl, mappings, sources, sourcesContent, names, stopLine, stopColumn) {\n    const map = AnyMap(section.map, mapUrl);\n    const { line: lineOffset, column: columnOffset } = section.offset;\n    const sourcesOffset = sources.length;\n    const namesOffset = names.length;\n    const decoded = decodedMappings(map);\n    const { resolvedSources } = map;\n    append(sources, resolvedSources);\n    append(sourcesContent, map.sourcesContent || fillSourcesContent(resolvedSources.length));\n    append(names, map.names);\n    // If this section jumps forwards several lines, we need to add lines to the output mappings catch up.\n    for (let i = mappings.length; i <= lineOffset; i++)\n        mappings.push([]);\n    // We can only add so many lines before we step into the range that the next section's map\n    // controls. When we get to the last line, then we'll start checking the segments to see if\n    // they've crossed into the column range.\n    const stopI = stopLine - lineOffset;\n    const len = Math.min(decoded.length, stopI + 1);\n    for (let i = 0; i < len; i++) {\n        const line = decoded[i];\n        // On the 0th loop, the line will already exist due to a previous section, or the line catch up\n        // loop above.\n        const out = i === 0 ? mappings[lineOffset] : (mappings[lineOffset + i] = []);\n        // On the 0th loop, the section's column offset shifts us forward. On all other lines (since the\n        // map can be multiple lines), it doesn't.\n        const cOffset = i === 0 ? columnOffset : 0;\n        for (let j = 0; j < line.length; j++) {\n            const seg = line[j];\n            const column = cOffset + seg[COLUMN];\n            // If this segment steps into the column range that the next section's map controls, we need\n            // to stop early.\n            if (i === stopI && column >= stopColumn)\n                break;\n            if (seg.length === 1) {\n                out.push([column]);\n                continue;\n            }\n            const sourcesIndex = sourcesOffset + seg[SOURCES_INDEX];\n            const sourceLine = seg[SOURCE_LINE];\n            const sourceColumn = seg[SOURCE_COLUMN];\n            if (seg.length === 4) {\n                out.push([column, sourcesIndex, sourceLine, sourceColumn]);\n                continue;\n            }\n            out.push([column, sourcesIndex, sourceLine, sourceColumn, namesOffset + seg[NAMES_INDEX]]);\n        }\n    }\n}\nfunction append(arr, other) {\n    for (let i = 0; i < other.length; i++)\n        arr.push(other[i]);\n}\n// Sourcemaps don't need to have sourcesContent, and if they don't, we need to create an array of\n// equal length to the sources. This is because the sources and sourcesContent are paired arrays,\n// where `sourcesContent[i]` is the content of the `sources[i]` file. If we didn't, then joined\n// sourcemap would desynchronize the sources/contents.\nfunction fillSourcesContent(len) {\n    const sourcesContent = [];\n    for (let i = 0; i < len; i++)\n        sourcesContent[i] = null;\n    return sourcesContent;\n}\n\nconst INVALID_ORIGINAL_MAPPING = Object.freeze({\n    source: null,\n    line: null,\n    column: null,\n    name: null,\n});\nconst INVALID_GENERATED_MAPPING = Object.freeze({\n    line: null,\n    column: null,\n});\nconst LINE_GTR_ZERO = '`line` must be greater than 0 (lines start at line 1)';\nconst COL_GTR_EQ_ZERO = '`column` must be greater than or equal to 0 (columns start at column 0)';\nconst LEAST_UPPER_BOUND = -1;\nconst GREATEST_LOWER_BOUND = 1;\n/**\n * Returns the encoded (VLQ string) form of the SourceMap's mappings field.\n */\nlet encodedMappings;\n/**\n * Returns the decoded (array of lines of segments) form of the SourceMap's mappings field.\n */\nlet decodedMappings;\n/**\n * A low-level API to find the segment associated with a generated line/column (think, from a\n * stack trace). Line and column here are 0-based, unlike `originalPositionFor`.\n */\nlet traceSegment;\n/**\n * A higher-level API to find the source/line/column associated with a generated line/column\n * (think, from a stack trace). Line is 1-based, but column is 0-based, due to legacy behavior in\n * `source-map` library.\n */\nlet originalPositionFor;\n/**\n * Finds the source/line/column directly after the mapping returned by originalPositionFor, provided\n * the found mapping is from the same source and line as the originalPositionFor mapping.\n *\n * Eg, in the code `let id = 1`, `originalPositionAfter` could find the mapping associated with `1`\n * using the same needle that would return `id` when calling `originalPositionFor`.\n */\nlet generatedPositionFor;\n/**\n * Iterates each mapping in generated position order.\n */\nlet eachMapping;\n/**\n * A helper that skips sorting of the input map's mappings array, which can be expensive for larger\n * maps.\n */\nlet presortedDecodedMap;\n/**\n * Returns a sourcemap object (with decoded mappings) suitable for passing to a library that expects\n * a sourcemap, or to JSON.stringify.\n */\nlet decodedMap;\n/**\n * Returns a sourcemap object (with encoded mappings) suitable for passing to a library that expects\n * a sourcemap, or to JSON.stringify.\n */\nlet encodedMap;\nclass TraceMap {\n    constructor(map, mapUrl) {\n        this._decodedMemo = memoizedState();\n        this._bySources = undefined;\n        this._bySourceMemos = undefined;\n        const isString = typeof map === 'string';\n        if (!isString && map.constructor === TraceMap)\n            return map;\n        const parsed = (isString ? JSON.parse(map) : map);\n        const { version, file, names, sourceRoot, sources, sourcesContent } = parsed;\n        this.version = version;\n        this.file = file;\n        this.names = names;\n        this.sourceRoot = sourceRoot;\n        this.sources = sources;\n        this.sourcesContent = sourcesContent;\n        if (sourceRoot || mapUrl) {\n            const from = resolve(sourceRoot || '', stripFilename(mapUrl));\n            this.resolvedSources = sources.map((s) => resolve(s || '', from));\n        }\n        else {\n            this.resolvedSources = sources.map((s) => s || '');\n        }\n        const { mappings } = parsed;\n        if (typeof mappings === 'string') {\n            this._encoded = mappings;\n            this._decoded = undefined;\n        }\n        else {\n            this._encoded = undefined;\n            this._decoded = maybeSort(mappings, isString);\n        }\n    }\n}\n(() => {\n    encodedMappings = (map) => {\n        var _a;\n        return ((_a = map._encoded) !== null && _a !== void 0 ? _a : (map._encoded = encode(map._decoded)));\n    };\n    decodedMappings = (map) => {\n        return (map._decoded || (map._decoded = decode(map._encoded)));\n    };\n    traceSegment = (map, line, column) => {\n        const decoded = decodedMappings(map);\n        // It's common for parent source maps to have pointers to lines that have no\n        // mapping (like a \"//# sourceMappingURL=\") at the end of the child file.\n        if (line >= decoded.length)\n            return null;\n        return traceSegmentInternal(decoded[line], map._decodedMemo, line, column, GREATEST_LOWER_BOUND);\n    };\n    originalPositionFor = (map, { line, column, bias }) => {\n        line--;\n        if (line < 0)\n            throw new Error(LINE_GTR_ZERO);\n        if (column < 0)\n            throw new Error(COL_GTR_EQ_ZERO);\n        const decoded = decodedMappings(map);\n        // It's common for parent source maps to have pointers to lines that have no\n        // mapping (like a \"//# sourceMappingURL=\") at the end of the child file.\n        if (line >= decoded.length)\n            return INVALID_ORIGINAL_MAPPING;\n        const segment = traceSegmentInternal(decoded[line], map._decodedMemo, line, column, bias || GREATEST_LOWER_BOUND);\n        if (segment == null)\n            return INVALID_ORIGINAL_MAPPING;\n        if (segment.length == 1)\n            return INVALID_ORIGINAL_MAPPING;\n        const { names, resolvedSources } = map;\n        return {\n            source: resolvedSources[segment[SOURCES_INDEX]],\n            line: segment[SOURCE_LINE] + 1,\n            column: segment[SOURCE_COLUMN],\n            name: segment.length === 5 ? names[segment[NAMES_INDEX]] : null,\n        };\n    };\n    generatedPositionFor = (map, { source, line, column, bias }) => {\n        line--;\n        if (line < 0)\n            throw new Error(LINE_GTR_ZERO);\n        if (column < 0)\n            throw new Error(COL_GTR_EQ_ZERO);\n        const { sources, resolvedSources } = map;\n        let sourceIndex = sources.indexOf(source);\n        if (sourceIndex === -1)\n            sourceIndex = resolvedSources.indexOf(source);\n        if (sourceIndex === -1)\n            return INVALID_GENERATED_MAPPING;\n        const generated = (map._bySources || (map._bySources = buildBySources(decodedMappings(map), (map._bySourceMemos = sources.map(memoizedState)))));\n        const memos = map._bySourceMemos;\n        const segments = generated[sourceIndex][line];\n        if (segments == null)\n            return INVALID_GENERATED_MAPPING;\n        const segment = traceSegmentInternal(segments, memos[sourceIndex], line, column, bias || GREATEST_LOWER_BOUND);\n        if (segment == null)\n            return INVALID_GENERATED_MAPPING;\n        return {\n            line: segment[REV_GENERATED_LINE] + 1,\n            column: segment[REV_GENERATED_COLUMN],\n        };\n    };\n    eachMapping = (map, cb) => {\n        const decoded = decodedMappings(map);\n        const { names, resolvedSources } = map;\n        for (let i = 0; i < decoded.length; i++) {\n            const line = decoded[i];\n            for (let j = 0; j < line.length; j++) {\n                const seg = line[j];\n                const generatedLine = i + 1;\n                const generatedColumn = seg[0];\n                let source = null;\n                let originalLine = null;\n                let originalColumn = null;\n                let name = null;\n                if (seg.length !== 1) {\n                    source = resolvedSources[seg[1]];\n                    originalLine = seg[2] + 1;\n                    originalColumn = seg[3];\n                }\n                if (seg.length === 5)\n                    name = names[seg[4]];\n                cb({\n                    generatedLine,\n                    generatedColumn,\n                    source,\n                    originalLine,\n                    originalColumn,\n                    name,\n                });\n            }\n        }\n    };\n    presortedDecodedMap = (map, mapUrl) => {\n        const clone = Object.assign({}, map);\n        clone.mappings = [];\n        const tracer = new TraceMap(clone, mapUrl);\n        tracer._decoded = map.mappings;\n        return tracer;\n    };\n    decodedMap = (map) => {\n        return {\n            version: 3,\n            file: map.file,\n            names: map.names,\n            sourceRoot: map.sourceRoot,\n            sources: map.sources,\n            sourcesContent: map.sourcesContent,\n            mappings: decodedMappings(map),\n        };\n    };\n    encodedMap = (map) => {\n        return {\n            version: 3,\n            file: map.file,\n            names: map.names,\n            sourceRoot: map.sourceRoot,\n            sources: map.sources,\n            sourcesContent: map.sourcesContent,\n            mappings: encodedMappings(map),\n        };\n    };\n})();\nfunction traceSegmentInternal(segments, memo, line, column, bias) {\n    let index = memoizedBinarySearch(segments, column, memo, line);\n    if (found) {\n        index = (bias === LEAST_UPPER_BOUND ? upperBound : lowerBound)(segments, column, index);\n    }\n    else if (bias === LEAST_UPPER_BOUND)\n        index++;\n    if (index === -1 || index === segments.length)\n        return null;\n    return segments[index];\n}\n\nexport { AnyMap, GREATEST_LOWER_BOUND, LEAST_UPPER_BOUND, TraceMap, decodedMap, decodedMappings, eachMapping, encodedMap, encodedMappings, generatedPositionFor, originalPositionFor, presortedDecodedMap, traceSegment };\n//# sourceMappingURL=trace-mapping.mjs.map\n","/**\n * Gets the index associated with `key` in the backing array, if it is already present.\n */\nlet get;\n/**\n * Puts `key` into the backing array, if it is not already present. Returns\n * the index of the `key` in the backing array.\n */\nlet put;\n/**\n * Pops the last added item out of the SetArray.\n */\nlet pop;\n/**\n * SetArray acts like a `Set` (allowing only one occurrence of a string `key`), but provides the\n * index of the `key` in the backing array.\n *\n * This is designed to allow synchronizing a second array with the contents of the backing array,\n * like how in a sourcemap `sourcesContent[i]` is the source content associated with `source[i]`,\n * and there are never duplicates.\n */\nclass SetArray {\n    constructor() {\n        this._indexes = { __proto__: null };\n        this.array = [];\n    }\n}\n(() => {\n    get = (strarr, key) => strarr._indexes[key];\n    put = (strarr, key) => {\n        // The key may or may not be present. If it is present, it's a number.\n        const index = get(strarr, key);\n        if (index !== undefined)\n            return index;\n        const { array, _indexes: indexes } = strarr;\n        return (indexes[key] = array.push(key) - 1);\n    };\n    pop = (strarr) => {\n        const { array, _indexes: indexes } = strarr;\n        if (array.length === 0)\n            return;\n        const last = array.pop();\n        indexes[last] = undefined;\n    };\n})();\n\nexport { SetArray, get, pop, put };\n//# sourceMappingURL=set-array.mjs.map\n","import { SetArray, put } from '@jridgewell/set-array';\nimport { encode } from '@jridgewell/sourcemap-codec';\nimport { TraceMap, decodedMappings } from '@jridgewell/trace-mapping';\n\nconst COLUMN = 0;\nconst SOURCES_INDEX = 1;\nconst SOURCE_LINE = 2;\nconst SOURCE_COLUMN = 3;\nconst NAMES_INDEX = 4;\n\nconst NO_NAME = -1;\n/**\n * A low-level API to associate a generated position with an original source position. Line and\n * column here are 0-based, unlike `addMapping`.\n */\nlet addSegment;\n/**\n * A high-level API to associate a generated position with an original source position. Line is\n * 1-based, but column is 0-based, due to legacy behavior in `source-map` library.\n */\nlet addMapping;\n/**\n * Same as `addSegment`, but will only add the segment if it generates useful information in the\n * resulting map. This only works correctly if segments are added **in order**, meaning you should\n * not add a segment with a lower generated line/column than one that came before.\n */\nlet maybeAddSegment;\n/**\n * Same as `addMapping`, but will only add the mapping if it generates useful information in the\n * resulting map. This only works correctly if mappings are added **in order**, meaning you should\n * not add a mapping with a lower generated line/column than one that came before.\n */\nlet maybeAddMapping;\n/**\n * Adds/removes the content of the source file to the source map.\n */\nlet setSourceContent;\n/**\n * Returns a sourcemap object (with decoded mappings) suitable for passing to a library that expects\n * a sourcemap, or to JSON.stringify.\n */\nlet toDecodedMap;\n/**\n * Returns a sourcemap object (with encoded mappings) suitable for passing to a library that expects\n * a sourcemap, or to JSON.stringify.\n */\nlet toEncodedMap;\n/**\n * Constructs a new GenMapping, using the already present mappings of the input.\n */\nlet fromMap;\n/**\n * Returns an array of high-level mapping objects for every recorded segment, which could then be\n * passed to the `source-map` library.\n */\nlet allMappings;\n// This split declaration is only so that terser can elminiate the static initialization block.\nlet addSegmentInternal;\n/**\n * Provides the state to generate a sourcemap.\n */\nclass GenMapping {\n    constructor({ file, sourceRoot } = {}) {\n        this._names = new SetArray();\n        this._sources = new SetArray();\n        this._sourcesContent = [];\n        this._mappings = [];\n        this.file = file;\n        this.sourceRoot = sourceRoot;\n    }\n}\n(() => {\n    addSegment = (map, genLine, genColumn, source, sourceLine, sourceColumn, name) => {\n        return addSegmentInternal(false, map, genLine, genColumn, source, sourceLine, sourceColumn, name);\n    };\n    maybeAddSegment = (map, genLine, genColumn, source, sourceLine, sourceColumn, name) => {\n        return addSegmentInternal(true, map, genLine, genColumn, source, sourceLine, sourceColumn, name);\n    };\n    addMapping = (map, mapping) => {\n        return addMappingInternal(false, map, mapping);\n    };\n    maybeAddMapping = (map, mapping) => {\n        return addMappingInternal(true, map, mapping);\n    };\n    setSourceContent = (map, source, content) => {\n        const { _sources: sources, _sourcesContent: sourcesContent } = map;\n        sourcesContent[put(sources, source)] = content;\n    };\n    toDecodedMap = (map) => {\n        const { file, sourceRoot, _mappings: mappings, _sources: sources, _sourcesContent: sourcesContent, _names: names, } = map;\n        removeEmptyFinalLines(mappings);\n        return {\n            version: 3,\n            file: file || undefined,\n            names: names.array,\n            sourceRoot: sourceRoot || undefined,\n            sources: sources.array,\n            sourcesContent,\n            mappings,\n        };\n    };\n    toEncodedMap = (map) => {\n        const decoded = toDecodedMap(map);\n        return Object.assign(Object.assign({}, decoded), { mappings: encode(decoded.map